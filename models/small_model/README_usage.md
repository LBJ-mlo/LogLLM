# LogLLM Small Model ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

è¿™æ˜¯åŸºäºMoEï¼ˆMixture of Expertsï¼‰æ¶æ„çš„æ—¥å¿—å¼‚å¸¸æ£€æµ‹æ¨¡å‹ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«æ—¥å¿—åºåˆ—ä¸­çš„å¼‚å¸¸æ¨¡å¼ã€‚æ¨¡å‹é‡‡ç”¨BERT+MoEçš„åŒå±‚æ¶æ„ï¼Œåœ¨è®­ç»ƒæ•°æ®ä¸Šè¾¾åˆ°äº†99.9%çš„å‡†ç¡®ç‡ã€‚

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

- **BERTç¼–ç å™¨**: bert-base-uncasedï¼Œæå–æ—¥å¿—æ¡ç›®è¯­ä¹‰ç‰¹å¾
- **MoEå±‚**: 4ä¸ªä¸“å®¶ï¼ŒTop-Pé—¨æ§æœºåˆ¶
- **è¾“å‡º**: äºŒåˆ†ç±»ï¼ˆæ­£å¸¸/å¼‚å¸¸ï¼‰
- **æ¨¡å‹å¤§å°**: ~500MB

## ğŸ“ æ–‡ä»¶ç»“æ„

```
small_model/
â”œâ”€â”€ bert-base-uncased/          # BERTé¢„è®­ç»ƒæ¨¡å‹
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ tokenizer_config.json
â”œâ”€â”€ final_moe_model/            # è®­ç»ƒå¥½çš„MoEæ¨¡å‹
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â””â”€â”€ ...
â”œâ”€â”€ moe_results/                # è®­ç»ƒæ£€æŸ¥ç‚¹
â”œâ”€â”€ moe_logs/                   # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ moe_log_detector.py         # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py                # æ¨ç†è„šæœ¬
â””â”€â”€ README_usage.md            # æœ¬ä½¿ç”¨æŒ‡å—
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

```bash
# åŸºç¡€ä¾èµ–
pip install torch>=1.9.0
pip install transformers>=4.20.0
pip install scikit-learn>=1.0.0
pip install numpy>=1.21.0

# å¯é€‰ï¼šGPUåŠ é€Ÿ
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### 2. åŸºæœ¬ä½¿ç”¨

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨æ¨ç†è„šæœ¬

```bash
# è¿è¡Œæ¨ç†æ¼”ç¤º
python inference.py
```

#### æ–¹æ³•äºŒï¼šä»£ç è°ƒç”¨

```python
from inference import LogAnomalyDetector

# åˆå§‹åŒ–æ£€æµ‹å™¨
detector = LogAnomalyDetector(
    model_path="./final_moe_model",
    bert_path="./bert-base-uncased"
)

# å‡†å¤‡æ—¥å¿—åºåˆ—
log_sequence = """
2024-01-01 10:00:01 INFO [System] Application started successfully
2024-01-01 10:00:02 ERROR [Database] Connection failed: timeout
2024-01-01 10:00:03 ERROR [Database] Retry connection failed
2024-01-01 10:00:04 ERROR [Database] Database service unavailable
2024-01-01 10:00:05 WARN [System] Application running in degraded mode
"""

# è¿›è¡Œé¢„æµ‹
result = detector.predict(log_sequence)
print(f"é¢„æµ‹ç»“æœ: {result['prediction']}")
print(f"ç½®ä¿¡åº¦: {result['confidence']:.4f}")
```

## ğŸ“Š è¾“å…¥æ ¼å¼

### æ—¥å¿—åºåˆ—æ ¼å¼

æ¨¡å‹æ¥å—å¤šè¡Œæ—¥å¿—åºåˆ—ï¼Œæ¯è¡Œä¸€æ¡æ—¥å¿—ï¼š

```python
log_sequence = """
2024-01-01 10:00:01 INFO [System] Application started successfully
2024-01-01 10:00:02 INFO [Database] Connection established
2024-01-01 10:00:03 INFO [API] Server listening on port 8080
2024-01-01 10:00:04 INFO [Cache] Redis cache initialized
2024-01-01 10:00:05 INFO [Auth] Authentication service ready
"""
```

### å‚æ•°è¯´æ˜

- **max_log_entry_length**: å•æ¡æ—¥å¿—æœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤128ï¼‰
- **max_sequence_length**: åºåˆ—æœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤32æ¡æ—¥å¿—ï¼‰

## ğŸ” è¾“å‡ºæ ¼å¼

### é¢„æµ‹ç»“æœ

```python
{
    "prediction": "å¼‚å¸¸",           # é¢„æµ‹æ ‡ç­¾ï¼šæ­£å¸¸/å¼‚å¸¸
    "confidence": 0.9992,          # ç½®ä¿¡åº¦ (0-1)
    "probabilities": {             # æ¦‚ç‡åˆ†å¸ƒ
        "æ­£å¸¸": 0.0008,
        "å¼‚å¸¸": 0.9992
    },
    "logits": [1.2, 8.5]          # åŸå§‹logitså€¼
}
```

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### 1. æ‰¹é‡æ¨ç†

```python
import json
from inference import LogAnomalyDetector

detector = LogAnomalyDetector()

# æ‰¹é‡æ—¥å¿—åºåˆ—
log_sequences = [
    "æ­£å¸¸æ—¥å¿—åºåˆ—1...",
    "å¼‚å¸¸æ—¥å¿—åºåˆ—1...",
    "æ­£å¸¸æ—¥å¿—åºåˆ—2...",
    # ...
]

results = []
for logs in log_sequences:
    result = detector.predict(logs)
    results.append(result)

# ä¿å­˜ç»“æœ
with open('inference_results.json', 'w', encoding='utf-8') as f:
    json.dump(results, f, ensure_ascii=False, indent=2)
```

### 2. è‡ªå®šä¹‰é¢„å¤„ç†

```python
# è‡ªå®šä¹‰é¢„å¤„ç†å‚æ•°
embeddings, attention_mask = detector.preprocess_log_sequence(
    log_sequence,
    max_log_entry_length=64,    # æ›´çŸ­çš„æ—¥å¿—é•¿åº¦
    max_sequence_length=16      # æ›´çŸ­çš„åºåˆ—é•¿åº¦
)
```

### 3. æ¨¡å‹é…ç½®

```python
# ä½¿ç”¨ä¸åŒçš„æ¨¡å‹è·¯å¾„
detector = LogAnomalyDetector(
    model_path="/path/to/your/model",
    bert_path="/path/to/bert/model"
)
```

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–

### 1. GPUåŠ é€Ÿ

```python
# è‡ªåŠ¨æ£€æµ‹GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")
```

### 2. æ‰¹å¤„ç†æ¨ç†

```python
# æ‰¹é‡å¤„ç†æé«˜æ•ˆç‡
def batch_predict(detector, log_sequences, batch_size=8):
    results = []
    for i in range(0, len(log_sequences), batch_size):
        batch = log_sequences[i:i+batch_size]
        # æ‰¹é‡å¤„ç†é€»è¾‘
        batch_results = [detector.predict(logs) for logs in batch]
        results.extend(batch_results)
    return results
```

## ğŸ“ˆ æ¨¡å‹æ€§èƒ½

### è®­ç»ƒç»“æœ

- **å‡†ç¡®ç‡**: 99.9%
- **ç²¾ç¡®ç‡**: 100.0%
- **å¬å›ç‡**: 99.8%
- **F1åˆ†æ•°**: 99.9%

### æ¨ç†æ€§èƒ½

- **å•æ¬¡æ¨ç†æ—¶é—´**: ~50ms (GPU)
- **å†…å­˜å ç”¨**: ~2GB (GPU)
- **æ”¯æŒåºåˆ—é•¿åº¦**: æœ€å¤š32æ¡æ—¥å¿—

## ğŸš¨ å¼‚å¸¸å¤„ç†

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```python
   # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
   import os
   if not os.path.exists("./final_moe_model"):
       raise FileNotFoundError("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
   ```

2. **å†…å­˜ä¸è¶³**
   ```python
   # ä½¿ç”¨CPUæ¨ç†
   detector = LogAnomalyDetector()
   # æˆ–è€…å‡å°‘batch_size
   ```

3. **è¾“å…¥æ ¼å¼é”™è¯¯**
   ```python
   # ç¡®ä¿æ—¥å¿—åºåˆ—æ ¼å¼æ­£ç¡®
   if not isinstance(log_sequence, str):
       raise ValueError("æ—¥å¿—åºåˆ—å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
   ```

## ğŸ”„ æ¨¡å‹æ›´æ–°

### é‡æ–°è®­ç»ƒ

```bash
# 1. å‡†å¤‡æ–°æ•°æ®
# 2. ä¿®æ”¹è®­ç»ƒå‚æ•°
# 3. è¿è¡Œè®­ç»ƒ
python moe_log_detector.py
```

### æ¨¡å‹ä¿å­˜

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åˆ°ï¼š
- `./moe_results/` - æ£€æŸ¥ç‚¹
- `./final_moe_model/` - æœ€ç»ˆæ¨¡å‹

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### æ—¥å¿—æ ¼å¼å»ºè®®

- ä½¿ç”¨æ ‡å‡†çš„æ—¶é—´æˆ³æ ¼å¼
- åŒ…å«æ—¥å¿—çº§åˆ«ï¼ˆINFO, ERROR, WARNç­‰ï¼‰
- ä¿æŒæ—¥å¿—å†…å®¹çš„ä¸€è‡´æ€§

### æ€§èƒ½è°ƒä¼˜

- æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´åºåˆ—é•¿åº¦
- ä½¿ç”¨GPUåŠ é€Ÿæ¨ç†
- æ‰¹é‡å¤„ç†æé«˜æ•ˆç‡

## ğŸ“ ç¤ºä¾‹ä»£ç 

### å®Œæ•´ç¤ºä¾‹

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from inference import LogAnomalyDetector
import json

def main():
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = LogAnomalyDetector()
    
    # æµ‹è¯•æ—¥å¿—åºåˆ—
    test_logs = [
        {
            "name": "æ­£å¸¸ç³»ç»Ÿå¯åŠ¨",
            "logs": """2024-01-01 10:00:01 INFO [System] Application started successfully
2024-01-01 10:00:02 INFO [Database] Connection established
2024-01-01 10:00:03 INFO [API] Server listening on port 8080"""
        },
        {
            "name": "æ•°æ®åº“è¿æ¥å¼‚å¸¸",
            "logs": """2024-01-01 10:00:01 INFO [System] Application started successfully
2024-01-01 10:00:02 ERROR [Database] Connection failed: timeout
2024-01-01 10:00:03 ERROR [Database] Retry connection failed"""
        }
    ]
    
    # æ‰¹é‡æ¨ç†
    for test in test_logs:
        print(f"\næµ‹è¯•: {test['name']}")
        print(f"æ—¥å¿—: {test['logs']}")
        
        result = detector.predict(test['logs'])
        print(f"ç»“æœ: {result['prediction']} (ç½®ä¿¡åº¦: {result['confidence']:.4f})")

if __name__ == "__main__":
    main()
```

---

**æ³¨æ„**: é¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½BERTæ¨¡å‹ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ã€‚å¦‚éœ€ç¦»çº¿ä½¿ç”¨ï¼Œè¯·æå‰ä¸‹è½½æ¨¡å‹æ–‡ä»¶ã€‚ 