# 日志异常检测项目总结文档

## 项目概述

本项目构建了一个完整的日志异常检测系统，包含数据生成、模型训练和部署的完整流程。系统采用双模型架构：小模型用于初步异常检测，大模型用于详细异常分析和分类。

## 项目结构

```
Log/
├── data/                          # 数据文件目录
│   ├── log_sequences_strings.json     # 8000条原始日志序列
│   ├── train_data.json               # 训练集(6400条)
│   ├── validation_data.json          # 验证集(800条)
│   ├── test_data.json                # 测试集(800条)
│   ├── unsloth_training_data.json    # Unsloth格式训练数据
│   └── anomaly_classification_dataset.json  # 异常分类数据集
├── models/                        # 模型训练目录
│   ├── small_model/              # 小模型训练
│   │   ├── moe_log_detector.py   # MoE模型训练脚本
│   │   ├── convert_data.py       # 数据格式转换脚本
│   │   ├── train.py              # 训练启动脚本
│   │   ├── requirements.txt      # 依赖包列表
│   │   └── README.md             # 小模型说明文档
│   └── large_model/              # 大模型微调
│       └── README.md             # 大模型说明文档
└── README.md                     # 项目总览
```

## 数据构造部分

### 1. 日志序列生成器 (`log_sequence_generator.py`)

**功能**: 生成模拟微服务日志序列数据

**特点**:
- 支持6-15条日志的序列长度
- 模拟5-10个微服务
- 包含正常和异常日志序列
- 支持多种异常类型（超时、错误、连接失败等）
- 输出格式：JSON和CSV
- 序列级异常判断（非单条日志）

**异常类型**:
- 超时异常
- 连接失败
- 数据库错误
- 服务调用失败
- 资源耗尽
- 权限错误

### 2. 异常分类数据生成器 (`anomaly_classification_generator.py`)

**功能**: 生成用于大模型微调的异常分类数据

**特点**:
- 生成4500条样本数据
- 生成2000条Unsloth格式训练数据
- 支持多异常类别分类
- 包含指令微调格式

### 3. 数据划分 (`data_splitter.py`)

**功能**: 将数据集划分为训练/验证/测试集

**划分比例**:
- 训练集: 6400条样本
- 验证集: 800条样本
- 测试集: 800条样本
- 使用分层抽样保持标签分布

### 4. 生成的数据文件

| 文件名 | 样本数 | 用途 |
|--------|--------|------|
| `log_sequences_strings.json` | 8000 | 原始日志序列数据 |
| `train_data.json` | 6400 | 模型训练集 |
| `validation_data.json` | 800 | 模型验证集 |
| `test_data.json` | 800 | 模型测试集 |
| `unsloth_training_data.json` | 2000 | Unsloth格式训练数据 |
| `anomaly_classification_dataset.json` | 4500 | 异常分类数据集 |

## 模型架构部分

### 1. 小模型（MoE架构）

**文件**: `models/small_model/moe_log_detector.py`

**架构特点**:
- 基于BERT预训练模型（bert-base-uncased）
- Top-P MoE层（4个专家）
- 多头自注意力机制（8个注意力头）
- 两阶段训练策略
- 序列级异常检测

**训练策略**:
1. **第一阶段**: 激活所有专家，无门控机制
2. **第二阶段**: 激活Top-P门控机制

**超参数**:
- 学习率: 1e-4
- 批次大小: 64
- 训练轮数: 2
- 专家数量: 4
- Top-P阈值: 0.8
- 隐藏层大小: 512
- 中间层大小: 256

**模型组件**:
- `MoEConfig`: 模型配置类
- `TopPMoE`: Top-P MoE层实现
- `EncoderWithMoE`: 主模型类
- `LogSequenceDataset`: 数据集类

### 2. 大模型微调（待开发）

**目录**: `models/large_model/`

**计划功能**:
- 基于大语言模型的指令微调
- 支持多种异常类型分类
- 生成式异常分析
- 中文日志优化

**技术栈**:
- 框架: Unsloth / Transformers
- 模型: Qwen / ChatGLM / Baichuan
- 微调方法: QLoRA / LoRA
- 评估: 自动评估 + 人工评估

## 数据格式规范

### 1. 日志序列格式
```json
{
    "sequence_id": "seq_001",
    "label": 0,  // 0:正常, 1:异常
    "length": 8,
    "log_entries": ["日志条目1", "日志条目2", ...]
}
```

### 2. 训练数据格式
```json
{
    "log_sequence": "日志条目1\n日志条目2\n...",
    "label": "正常" 或 "异常"
}
```

### 3. Unsloth格式（大模型微调）
```json
{
    "instruction": "分析以下日志序列，判断是否存在异常：",
    "input": "日志序列内容...",
    "output": "分析结果和建议..."
}
```

## 技术栈

### 数据处理
- Python 3.8+
- JSON/CSV处理
- scikit-learn（数据划分和评估）

### 小模型
- PyTorch 1.9+
- Transformers 4.20+
- BERT预训练模型
- MoE（Mixture of Experts）架构

### 大模型（计划）
- Unsloth框架
- QLoRA微调
- 大语言模型（Qwen/ChatGLM/Baichuan）

### 评估指标
- 准确率（Accuracy）
- 精确率（Precision）
- 召回率（Recall）
- F1分数（F1-Score）

## 使用流程

### 1. 数据准备
```bash
# 生成日志序列数据
python log_sequence_generator.py

# 划分数据集
python data_splitter.py

# 生成异常分类数据
python anomaly_classification_generator.py
```

### 2. 小模型训练
```bash
cd models/small_model
pip install -r requirements.txt
python train.py
```

### 3. 大模型微调（待开发）
```bash
cd models/large_model
# 待开发脚本
```

## 关键特性

### 1. 序列级异常检测
- 不是单条日志异常检测
- 基于日志序列的上下文分析
- 支持6-15条日志的序列长度

### 2. 多异常类型支持
- 系统异常
- 网络异常
- 数据库异常
- 应用异常
- 安全异常

### 3. 两阶段训练策略
- 第一阶段：专家预训练
- 第二阶段：门控机制训练

### 4. 中文日志支持
- 专门针对中文日志优化
- 支持中文异常类型分类

### 5. 完整训练流程
- 数据生成和预处理
- 模型训练和验证
- 性能评估和优化
- 模型保存和部署

## 性能指标

### 小模型预期性能
- 准确率: >90%
- 精确率: >85%
- 召回率: >80%
- F1分数: >82%

### 大模型预期性能
- 异常分类准确率: >95%
- 异常分析质量: 高质量
- 推理速度: 实时

## 部署建议

### 1. 环境要求
- GPU: NVIDIA GPU (推荐8GB+显存)
- 内存: 16GB+
- 存储: 50GB+可用空间

### 2. 依赖安装
```bash
pip install torch transformers scikit-learn numpy tqdm datasets accelerate
```

### 3. 模型部署
- 小模型：用于实时异常检测
- 大模型：用于详细异常分析
- API服务：提供RESTful接口

## 扩展计划

### 1. 短期目标
- 完成大模型微调脚本
- 优化模型性能
- 添加更多异常类型

### 2. 中期目标
- 构建完整的推理服务
- 支持实时日志流处理
- 添加可视化界面

### 3. 长期目标
- 支持多语言日志
- 集成更多预训练模型
- 构建企业级解决方案

## 注意事项

1. **数据安全**: 确保日志数据的安全性，避免敏感信息泄露
2. **模型更新**: 定期更新模型以适应新的异常模式
3. **性能监控**: 持续监控模型性能，及时调整参数
4. **资源管理**: 合理分配计算资源，避免资源浪费

---

**项目状态**: 小模型训练部分已完成，大模型微调部分待开发
**最后更新**: 2024年
**维护者**: 项目团队 